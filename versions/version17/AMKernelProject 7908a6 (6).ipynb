{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from nltk.classify.scikitlearn import SklearnClassifier\nfrom sklearn.naive_bayes import MultinomialNB,BernoulliNB\nfrom sklearn.linear_model import LogisticRegression,SGDClassifier\nfrom sklearn.svm import SVC, LinearSVC, NuSVC\nfrom sklearn import linear_model\nimport nltk\nimport random\nimport re\nimport nltk.corpus\nimport sklearn\nimport numpy\nimport csv\nfrom sklearn import metrics\nimport sys\nfrom nltk.stem.snowball import SnowballStemmer\nstemmer = SnowballStemmer(\"english\", ignore_stopwords=True) #se não ignorar os stopwords, não vai remover eles depois\n\n#inicializando bag de stopwords\nstopwords = nltk.corpus.stopwords.words('english')\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":50,"outputs":[{"output_type":"stream","text":"['cleandata', 'jigsaw-unintended-bias-in-toxicity-classification']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"base = []\ncsvFile = \"../input/cleandata/cleanDataTrain.csv\"\n\nbaseTrain = []\nlabels = []\nallWords = []\nwith open(csvFile) as csvfile:\n    import codecs\n    ifile = open(csvFile, \"rb\")\n    read = csv.reader(codecs.iterdecode(ifile, 'utf-8'))\n\n    for row in read:\n        try:\n            temp1 = row[1]\n            allWords.append(temp1)\n            baseTrain.append(temp1)\n            temp2 = float(row[0])\n            labels.append(temp2)\n        except IndexError:\n            pass","execution_count":51,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"baseTest = []\ncsvFile = \"../input/cleandata/cleanDataTest.csv\"\nids = []\nwith open(csvFile) as csvfile:\n    import codecs\n    ifile = open(csvFile, \"rb\")\n    read = csv.reader(codecs.iterdecode(ifile, 'utf-8'))\n\n    for row in read:\n        try:\n            # Se for pegar o valor float\n            temp2 = row[0]\n            temp1 = row[1]\n            if(temp2!=\"id\"):\n                baseTest.append(temp1)\n                ids.append(temp2)\n        except IndexError:\n            pass","execution_count":52,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = baseTrain\ny = labels","execution_count":53,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_min = []\ny_min = []\nfor u in range(len(y)):\n    if(y[u]!=0):\n        x_min.append(x[u])\n        y_min.append(y[u])","execution_count":54,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n#vectorizer_TF = CountVectorizer()\n#X_TFIDF = vectorizer_TF.fit_transform(x_min)\n#X_TestTFIDF = vectorizer_TF.transform(baseTest)","execution_count":55,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer_TFIDF = TfidfVectorizer(min_df=0.005)\nX_TFIDF = vectorizer_TFIDF.fit_transform(x_min)\nX_TestTFIDF = vectorizer_TFIDF.transform(baseTest)","execution_count":56,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_TFIDF, y_min, test_size=0.10, random_state=42)","execution_count":57,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train[0].shape","execution_count":58,"outputs":[{"output_type":"execute_result","execution_count":58,"data":{"text/plain":"(1, 1052)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\nfrom keras.layers import Input, LSTM, MaxPooling1D, Conv1D\nfrom keras.models import Model\n\n#X_train = X_train[:200000]\n#y_train = y_train[:200000]\n\ninput_layer = Input(shape=X_train[0].shape)\nconv1 = Conv1D(filters=32,\n               kernel_size=8,\n               strides=1,\n               activation='relu',\n               padding='same')(input_layer)\nlstm1 = LSTM(32, return_sequences=True)(conv1)\nconv2 = Conv1D(filters=32,\n               kernel_size=8,\n               strides=1,\n               activation='relu',\n               padding='same')(lstm1)\nlstm2 = LSTM(32, return_sequences=True)(conv2)\nconv3 = Conv1D(filters=32,\n               kernel_size=8,\n               strides=1,\n               activation='relu',\n               padding='same')(lstm2)\nlstm3 = LSTM(32, return_sequences=True)(conv3)\noutput_layer = Dense(1, activation='sigmoid')(lstm3)\nmodel = Model(inputs=input_layer, outputs=output_layer)\n\nmodel.summary()\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n#Classificação com probabilidade\ny_train_class = []\nfor t in range(len(y_train)):\n    if(y_train[t]<0.5):\n        y_train_class.append(0)\n    else:\n        y_train_class.append(1)\n\n#X_test = (X_test.toarray()).reshape(1,X_test.shape[0], X_test.shape[1])\ny_train_class = numpy.asarray(y_train_class)\ny_train_class.reshape(1,len(y_train_class),1)\nX_train = (X_train.toarray()).reshape(X_train.shape[0],1, X_train.shape[1])\n\nprint(X_train.shape)\nprint(y_train_class.shape)\ny_train_class = numpy.expand_dims(y_train_class, axis=1)\nprint(y_train_class.shape)\ny_train_class = numpy.expand_dims(y_train_class, axis=2)\nprint(y_train_class.shape)\n\nmodel.fit(X_train, y_train_class, epochs=100, batch_size=1024)\nscores = model.evaluate(X_train, y_train_class)\nprint(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))","execution_count":59,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_5 (InputLayer)         (None, 1, 1052)           0         \n_________________________________________________________________\nconv1d_5 (Conv1D)            (None, 1, 32)             269344    \n_________________________________________________________________\nlstm_5 (LSTM)                (None, 1, 32)             8320      \n_________________________________________________________________\nconv1d_6 (Conv1D)            (None, 1, 32)             8224      \n_________________________________________________________________\nlstm_6 (LSTM)                (None, 1, 32)             8320      \n_________________________________________________________________\nconv1d_7 (Conv1D)            (None, 1, 32)             8224      \n_________________________________________________________________\nlstm_7 (LSTM)                (None, 1, 32)             8320      \n_________________________________________________________________\ndense_5 (Dense)              (None, 1, 1)              33        \n=================================================================\nTotal params: 310,785\nTrainable params: 310,785\nNon-trainable params: 0\n_________________________________________________________________\n(486099, 1, 1052)\n(486099,)\n(486099, 1)\n(486099, 1, 1)\nEpoch 1/100\n486099/486099 [==============================] - 12s 25us/step - loss: 0.4883 - acc: 0.7824\nEpoch 2/100\n486099/486099 [==============================] - 9s 19us/step - loss: 0.4347 - acc: 0.8117\nEpoch 3/100\n486099/486099 [==============================] - 10s 20us/step - loss: 0.4329 - acc: 0.8121\nEpoch 4/100\n486099/486099 [==============================] - 10s 20us/step - loss: 0.4313 - acc: 0.8131\nEpoch 5/100\n486099/486099 [==============================] - 9s 19us/step - loss: 0.4297 - acc: 0.8137\nEpoch 6/100\n486099/486099 [==============================] - 9s 19us/step - loss: 0.4274 - acc: 0.8148\nEpoch 7/100\n486099/486099 [==============================] - 9s 19us/step - loss: 0.4255 - acc: 0.8156\nEpoch 8/100\n486099/486099 [==============================] - 9s 19us/step - loss: 0.4239 - acc: 0.8164\nEpoch 9/100\n486099/486099 [==============================] - 9s 19us/step - loss: 0.4222 - acc: 0.8172\nEpoch 10/100\n486099/486099 [==============================] - 9s 19us/step - loss: 0.4206 - acc: 0.8180\nEpoch 11/100\n486099/486099 [==============================] - 9s 19us/step - loss: 0.4189 - acc: 0.8187\nEpoch 12/100\n486099/486099 [==============================] - 9s 19us/step - loss: 0.4172 - acc: 0.8192\nEpoch 13/100\n486099/486099 [==============================] - 9s 19us/step - loss: 0.4156 - acc: 0.8202\nEpoch 14/100\n486099/486099 [==============================] - 9s 19us/step - loss: 0.4136 - acc: 0.8211\nEpoch 15/100\n486099/486099 [==============================] - 9s 19us/step - loss: 0.4118 - acc: 0.8218\nEpoch 16/100\n486099/486099 [==============================] - 9s 19us/step - loss: 0.4097 - acc: 0.8228\nEpoch 17/100\n486099/486099 [==============================] - 9s 19us/step - loss: 0.4076 - acc: 0.8239\nEpoch 18/100\n486099/486099 [==============================] - 9s 19us/step - loss: 0.4053 - acc: 0.8248\nEpoch 19/100\n486099/486099 [==============================] - 9s 19us/step - loss: 0.4034 - acc: 0.8255\nEpoch 20/100\n486099/486099 [==============================] - 9s 19us/step - loss: 0.4013 - acc: 0.8268\nEpoch 21/100\n486099/486099 [==============================] - 9s 19us/step - loss: 0.3996 - acc: 0.8275\nEpoch 22/100\n486099/486099 [==============================] - 9s 19us/step - loss: 0.3975 - acc: 0.8283\nEpoch 23/100\n486099/486099 [==============================] - 9s 19us/step - loss: 0.3959 - acc: 0.8293\nEpoch 24/100\n486099/486099 [==============================] - 9s 19us/step - loss: 0.3941 - acc: 0.8303\nEpoch 25/100\n265216/486099 [===============>..............] - ETA: 4s - loss: 0.3909 - acc: 0.8321","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-59-e74896834a1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n%s: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n#y_pred = clf.predict(X_test) \nX_test = (X_test.toarray()).reshape(X_test.shape[0], 1, X_test.shape[1])\ny_pred = model.predict(X_test) \ny_pred_prob = y_pred\n#print(y_pred_prob)\n#print(X_test.shape)\n\ny_pred_class = []\ny_test_class = []\ny_pred_prob_tox = []\n\nfor t in range(len(y_pred)):\n    if(y_pred[t][0]<0.5):\n        y_pred_class.append(0)\n    else:\n        y_pred_class.append(1)\n\nfor t in range(len(y_test)):\n    if(y_test[t]<0.5):\n        y_test_class.append(0)\n    else:\n        y_test_class.append(1)\n#    y_pred_prob_tox.append(y_pred_prob[t][0])\n\n#print(y_test_class[0], y_pred_class[0])\n#print(y_test.shape)\n#print(y_pred.shape)\ny_pred = y_pred.reshape(y_pred.shape[0], y_pred.shape[1])\n\nmse = metrics.mean_squared_error(y_test, y_pred)\nauc = metrics.roc_auc_score(y_test_class, y_pred_class)\nacc = metrics.accuracy_score(y_test_class, y_pred_class)\nprec = metrics.precision_score(y_test_class, y_pred_class)\nrec = metrics.recall_score(y_test_class, y_pred_class)\n\nprint(auc)\nprint(acc)\nprint(prec)\nprint(rec)\nprint(mse)\n\nwith open('results_validation.csv', mode='w') as employee_file:\n    writer = csv.writer(employee_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n    writer.writerow([\"Logistic Regression\"])\n    writer.writerow([\"mse: \", mse])\n    writer.writerow([\"auc: \", auc])\n    writer.writerow([\"accuracy: \", acc])\n    writer.writerow([\"precision: \", prec])\n    writer.writerow([\"recall: \", rec])","execution_count":41,"outputs":[{"output_type":"stream","text":"0.700945261184793\n0.8136861009794302\n0.7381191993738119\n0.4608993157380254\n0.04751784805741493\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_TestTFIDF = (X_TestTFIDF.toarray()).reshape(X_TestTFIDF.shape[0], 1, X_TestTFIDF.shape[1])\ny_pred_test = model.predict(X_TestTFIDF)\nwith open('submission.csv', mode='w') as employee_file:\n    \n    writer = csv.writer(employee_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n    writer.writerow([\"id\", \"prediction\"])\n    for id in range(len(ids)):\n        print(ids[id])\n        print(y_pred_test[id][0][0])\n        writer.writerow([ids[id], y_pred_test[id][0][0]])","execution_count":49,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'numpy.ndarray' object has no attribute 'toarray'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-49-4d79ae36a980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_TestTFIDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_TestTFIDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_TestTFIDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_TestTFIDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_TestTFIDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0memployee_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memployee_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquotechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\"'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquoting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQUOTE_MINIMAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'toarray'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}