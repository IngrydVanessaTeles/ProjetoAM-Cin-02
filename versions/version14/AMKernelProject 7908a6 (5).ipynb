{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from nltk.classify.scikitlearn import SklearnClassifier\nfrom sklearn.naive_bayes import MultinomialNB,BernoulliNB\nfrom sklearn.linear_model import LogisticRegression,SGDClassifier\nfrom sklearn.svm import SVC, LinearSVC, NuSVC\nfrom sklearn import linear_model\nimport nltk\nimport random\nimport re\nimport nltk.corpus\nimport sklearn\nimport numpy\nimport csv\nfrom sklearn import metrics\nimport sys\nfrom nltk.stem.snowball import SnowballStemmer\nstemmer = SnowballStemmer(\"english\", ignore_stopwords=True) #se não ignorar os stopwords, não vai remover eles depois\n\n#inicializando bag de stopwords\nstopwords = nltk.corpus.stopwords.words('english')\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":1,"outputs":[{"output_type":"stream","text":"['cleandata', 'jigsaw-unintended-bias-in-toxicity-classification']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"base = []\ncsvFile = \"../input/cleandata/cleanDataTrain.csv\"\n\nbaseTrain = []\nlabels = []\nallWords = []\nwith open(csvFile) as csvfile:\n    import codecs\n    ifile = open(csvFile, \"rb\")\n    read = csv.reader(codecs.iterdecode(ifile, 'utf-8'))\n\n    for row in read:\n        try:\n            temp1 = row[1]\n            allWords.append(temp1)\n            baseTrain.append(temp1)\n            temp2 = float(row[0])\n            labels.append(temp2)\n        except IndexError:\n            pass","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"baseTest = []\ncsvFile = \"../input/cleandata/cleanDataTest.csv\"\nids = []\nwith open(csvFile) as csvfile:\n    import codecs\n    ifile = open(csvFile, \"rb\")\n    read = csv.reader(codecs.iterdecode(ifile, 'utf-8'))\n\n    for row in read:\n        try:\n            # Se for pegar o valor float\n            temp2 = row[0]\n            temp1 = row[1]\n            if(temp2!=\"id\"):\n                baseTest.append(temp1)\n                ids.append(temp2)\n        except IndexError:\n            pass","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = baseTrain\ny = labels","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_min = []\ny_min = []\nfor u in range(len(y)):\n    if(y[u]!=0):\n        x_min.append(x[u])\n        y_min.append(y[u])","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n#vectorizer_TF = CountVectorizer()\n#X_TFIDF = vectorizer_TF.fit_transform(x_min)\n#X_TestTFIDF = vectorizer_TF.transform(baseTest)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer_TFIDF = TfidfVectorizer(min_df=0.001)\nX_TFIDF = vectorizer_TFIDF.fit_transform(x_min)\nX_TestTFIDF = vectorizer_TFIDF.transform(baseTest)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_TFIDF, y_min, test_size=0.10, random_state=42)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout\n\nmodel = Sequential()\nmodel.add(Dense(X_train.shape[1], input_dim=X_train.shape[1], activation='relu'))\n#model.add(Dense(1000, activation='relu'))\n\nmodel.add(Dense(1024))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1024))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1024))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n#Classificação com probabilidade\ny_train_class = []\nfor t in range(len(y_train)):\n    if(y_train[t]<0.5):\n        y_train_class.append(0)\n    else:\n        y_train_class.append(1)\n\nmodel.fit(X_train, y_train_class, epochs=10, batch_size=1024)\nscores = model.evaluate(X_train, y_train_class)\nprint(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))","execution_count":14,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n486099/486099 [==============================] - 17s 35us/step - loss: 0.4317 - acc: 0.8102\nEpoch 2/10\n486099/486099 [==============================] - 16s 32us/step - loss: 0.3676 - acc: 0.8412\nEpoch 3/10\n486099/486099 [==============================] - 16s 32us/step - loss: 0.2062 - acc: 0.9175\nEpoch 4/10\n486099/486099 [==============================] - 16s 32us/step - loss: 0.0712 - acc: 0.9748\nEpoch 5/10\n486099/486099 [==============================] - 16s 32us/step - loss: 0.0438 - acc: 0.9849\nEpoch 6/10\n486099/486099 [==============================] - 16s 32us/step - loss: 0.0341 - acc: 0.9875\nEpoch 7/10\n486099/486099 [==============================] - 16s 32us/step - loss: 0.0299 - acc: 0.9885\nEpoch 8/10\n486099/486099 [==============================] - 16s 32us/step - loss: 0.0270 - acc: 0.9894\nEpoch 9/10\n486099/486099 [==============================] - 16s 32us/step - loss: 0.0257 - acc: 0.9898\nEpoch 10/10\n486099/486099 [==============================] - 16s 33us/step - loss: 0.0240 - acc: 0.9904\n486099/486099 [==============================] - 30s 61us/step\n\nacc: 99.28%\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\n#y_pred = clf.predict(X_test) \ny_pred = model.predict(X_test) \ny_pred_prob = y_pred\nprint(y_pred_prob)\nprint(X_test.shape)\n\ny_pred_class = []\ny_test_class = []\ny_pred_prob_tox = []\n\nfor t in range(len(y_pred)):\n    if(y_pred[t][0]<0.5):\n        y_pred_class.append(0)\n    else:\n        y_pred_class.append(1)\n\nfor t in range(len(y_test)):\n    if(y_test[t]<0.5):\n        y_test_class.append(0)\n    else:\n        y_test_class.append(1)\n#    y_pred_prob_tox.append(y_pred_prob[t][0])\n\nprint(y_test_class[0], y_pred_class[0])\n\nmse = metrics.mean_squared_error(y_test, y_pred)\nauc = metrics.roc_auc_score(y_test_class, y_pred_class)\nacc = metrics.accuracy_score(y_test_class, y_pred_class)\nprec = metrics.precision_score(y_test_class, y_pred_class)\nrec = metrics.recall_score(y_test_class, y_pred_class)\n\nprint(auc)\nprint(acc)\nprint(prec)\nprint(rec)\nprint(mse)\n\nwith open('results_validation.csv', mode='w') as employee_file:\n    writer = csv.writer(employee_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n    writer.writerow([\"Logistic Regression\"])\n    writer.writerow([\"mse: \", mse])\n    writer.writerow([\"auc: \", auc])\n    writer.writerow([\"accuracy: \", acc])\n    writer.writerow([\"precision: \", prec])\n    writer.writerow([\"recall: \", rec])","execution_count":15,"outputs":[{"output_type":"stream","text":"[[1.9572204e-01]\n [9.9995512e-01]\n [2.6923418e-04]\n ...\n [4.0402937e-01]\n [5.6487853e-03]\n [1.6981879e-02]]\n(54011, 3303)\n1 0\n0.7275158161436068\n0.8018736923959934\n0.6427501379799732\n0.5691942466136014\n0.12266996438292371\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_test = model.predict(X_TestTFIDF)\nwith open('submission.csv', mode='w') as employee_file:\n    \n    writer = csv.writer(employee_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n    writer.writerow([\"id\", \"prediction\"])\n    for id in range(len(ids)):\n        print(ids[id])\n        print(y_pred_test[id])\n        writer.writerow([ids[id], y_pred_test[id][0]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}